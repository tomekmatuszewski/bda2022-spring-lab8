{"cells":[{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.feature import CountVectorizer, Tokenizer\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7aca5570-ef69-411b-94ce-fb6c0a1addd8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Prepare training documents, which are labeled.\ntraining = spark.createDataFrame([\n    (0, \"a b c d e spark\", 1.0),\n    (1, \"b d\", 0.0),\n    (2, \"spark f g h\", 1.0),\n    (3, \"hadoop mapreduce\", 0.0),\n    (4, \"b spark who\", 1.0),\n    (5, \"g d a y\", 0.0),\n    (6, \"spark fly\", 1.0),\n    (7, \"was mapreduce\", 0.0),\n    (8, \"e spark program\", 1.0),\n    (9, \"a e c l\", 0.0),\n    (10, \"spark compile\", 1.0),\n    (11, \"hadoop software\", 0.0)\n], [\"id\", \"text\", \"label\"])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ea1fd6ac-2e3b-4f16-9eb8-71599aa4515a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and lr.\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\ncount_vectorizer = CountVectorizer(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\nlr = LogisticRegression(maxIter=10)\npipeline = Pipeline(stages=[tokenizer, count_vectorizer, lr])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8eb31b88-9012-4451-8131-141e37e14bed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# We use a ParamGridBuilder to construct a grid of parameters to search over.\n# With 3 values for count_vectorizer.vocabSize and 2 values for lr.regParam,\n# this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.\nparamGrid = ParamGridBuilder() \\\n    .addGrid(count_vectorizer.vocabSize, [1024, 16384, 262144]) \\\n    .addGrid(lr.regParam, [0.1, 0.01]) \\\n    .build()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c62ad86f-c540-4ea3-bf04-ec26b74c3f0d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\ncross_val = CrossValidator(estimator=pipeline,\n                           estimatorParamMaps=paramGrid,\n                           evaluator=BinaryClassificationEvaluator(),\n                           numFolds=2) # use 3+ folds in practice"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1b78f08-d892-4310-ad4a-863a1c86d3aa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Run cross-validation, and choose the best set of parameters.\ncvModel = cross_val.fit(training)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe1b213a-d6f2-4b4f-bf25-4cfb6c652eeb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"\\nModel was fit using parameters: \")\nprint(cvModel.extractParamMap())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71c4b0bb-a4c7-44b6-b8a7-4ccfa5f5bac0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\nModel was fit using parameters: \n{Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;seed&#39;, doc=&#39;random seed.&#39;): 7809051150349531440, Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;numFolds&#39;, doc=&#39;number of folds for cross validation&#39;): 2, Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;foldCol&#39;, doc=&#34;Param for the column name of user specified fold number. Once this is specified, :py:class:`CrossValidator` won&#39;t do random k-fold split. Note that this column should be integer type with range [0, numFolds) and Spark will throw exception on out-of-range fold numbers.&#34;): &#39;&#39;, Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;estimator&#39;, doc=&#39;estimator to be cross-validated&#39;): Pipeline_4c1a9f170ba5, Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;estimatorParamMaps&#39;, doc=&#39;estimator param maps&#39;): [{Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 1024, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 1024, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 16384, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 16384, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 262144, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 262144, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}], Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;evaluator&#39;, doc=&#39;evaluator used to select hyper-parameters that maximize the validator metric&#39;): BinaryClassificationEvaluator_461facc334aa}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nModel was fit using parameters: \n{Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;seed&#39;, doc=&#39;random seed.&#39;): 7809051150349531440, Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;numFolds&#39;, doc=&#39;number of folds for cross validation&#39;): 2, Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;foldCol&#39;, doc=&#34;Param for the column name of user specified fold number. Once this is specified, :py:class:`CrossValidator` won&#39;t do random k-fold split. Note that this column should be integer type with range [0, numFolds) and Spark will throw exception on out-of-range fold numbers.&#34;): &#39;&#39;, Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;estimator&#39;, doc=&#39;estimator to be cross-validated&#39;): Pipeline_4c1a9f170ba5, Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;estimatorParamMaps&#39;, doc=&#39;estimator param maps&#39;): [{Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 1024, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 1024, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 16384, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 16384, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 262144, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1}, {Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 262144, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.01}], Param(parent=&#39;CrossValidatorModel_698659934567&#39;, name=&#39;evaluator&#39;, doc=&#39;evaluator used to select hyper-parameters that maximize the validator metric&#39;): BinaryClassificationEvaluator_461facc334aa}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"\\nThe best model was fit using parameters: \")\nprint(\"\\nTokenizer: \")\nprint(cvModel.bestModel.stages[0].extractParamMap())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bd5f1e1-11dc-4c12-bf92-4d0a5a876975"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\nThe best model was fit using parameters: \n\nTokenizer: \n{Param(parent=&#39;Tokenizer_7ce745d33d54&#39;, name=&#39;outputCol&#39;, doc=&#39;output column name.&#39;): &#39;words&#39;, Param(parent=&#39;Tokenizer_7ce745d33d54&#39;, name=&#39;inputCol&#39;, doc=&#39;input column name.&#39;): &#39;text&#39;}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nThe best model was fit using parameters: \n\nTokenizer: \n{Param(parent=&#39;Tokenizer_7ce745d33d54&#39;, name=&#39;outputCol&#39;, doc=&#39;output column name.&#39;): &#39;words&#39;, Param(parent=&#39;Tokenizer_7ce745d33d54&#39;, name=&#39;inputCol&#39;, doc=&#39;input column name.&#39;): &#39;text&#39;}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"\\nCount vectorizer: \")\nprint(cvModel.bestModel.stages[1].extractParamMap())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25a4191a-5496-4ccd-87a1-89dd8b3e36db"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\nCount vectorizer: \n{Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;binary&#39;, doc=&#39;Binary toggle to control the output vector values. If True, all nonzero counts (after minTF filter applied) are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts. Default False&#39;): False, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;maxDF&#39;, doc=&#39;Specifies the maximum number of different documents a term could appear in to be included in the vocabulary. A term that appears more than the threshold will be ignored. If this is an integer &gt;= 1, this specifies the maximum number of documents the term could appear in; if this is a double in [0,1), then this specifies the maximum fraction of documents the term could appear in. Default (2^63) - 1&#39;): 9.223372036854776e+18, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;minDF&#39;, doc=&#39;Specifies the minimum number of different documents a term must appear in to be included in the vocabulary. If this is an integer &gt;= 1, this specifies the number of documents the term must appear in; if this is a double in [0,1), then this specifies the fraction of documents. Default 1.0&#39;): 1.0, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;minTF&#39;, doc=&#34;Filter to ignore rare words in a document. For each document, terms with frequency/count less than the given threshold are ignored. If this is an integer &gt;= 1, then this specifies a count (of times the term must appear in the document); if this is a double in [0,1), then this specifies a fraction (out of the document&#39;s token count). Note that the parameter is only used in transform of CountVectorizerModel and does not affect fitting. Default 1.0&#34;): 1.0, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;outputCol&#39;, doc=&#39;output column name.&#39;): &#39;features&#39;, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 1024, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;inputCol&#39;, doc=&#39;input column name.&#39;): &#39;words&#39;}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nCount vectorizer: \n{Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;binary&#39;, doc=&#39;Binary toggle to control the output vector values. If True, all nonzero counts (after minTF filter applied) are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts. Default False&#39;): False, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;maxDF&#39;, doc=&#39;Specifies the maximum number of different documents a term could appear in to be included in the vocabulary. A term that appears more than the threshold will be ignored. If this is an integer &gt;= 1, this specifies the maximum number of documents the term could appear in; if this is a double in [0,1), then this specifies the maximum fraction of documents the term could appear in. Default (2^63) - 1&#39;): 9.223372036854776e+18, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;minDF&#39;, doc=&#39;Specifies the minimum number of different documents a term must appear in to be included in the vocabulary. If this is an integer &gt;= 1, this specifies the number of documents the term must appear in; if this is a double in [0,1), then this specifies the fraction of documents. Default 1.0&#39;): 1.0, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;minTF&#39;, doc=&#34;Filter to ignore rare words in a document. For each document, terms with frequency/count less than the given threshold are ignored. If this is an integer &gt;= 1, then this specifies a count (of times the term must appear in the document); if this is a double in [0,1), then this specifies a fraction (out of the document&#39;s token count). Note that the parameter is only used in transform of CountVectorizerModel and does not affect fitting. Default 1.0&#34;): 1.0, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;outputCol&#39;, doc=&#39;output column name.&#39;): &#39;features&#39;, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;vocabSize&#39;, doc=&#39;max size of the vocabulary. Default 1 &lt;&lt; 18.&#39;): 1024, Param(parent=&#39;CountVectorizer_094638eb05f5&#39;, name=&#39;inputCol&#39;, doc=&#39;input column name.&#39;): &#39;words&#39;}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"\\nLogistic regression: \")\nprint(cvModel.bestModel.stages[2].extractParamMap())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc9bfa6d-b861-4c3f-9ea6-d72f98bd8b6d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\nLogistic regression: \n{Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;aggregationDepth&#39;, doc=&#39;suggested depth for treeAggregate (&gt;= 2).&#39;): 2, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 0.0, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;family&#39;, doc=&#39;The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial&#39;): &#39;auto&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;featuresCol&#39;, doc=&#39;features column name.&#39;): &#39;features&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;fitIntercept&#39;, doc=&#39;whether to fit an intercept term.&#39;): True, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;labelCol&#39;, doc=&#39;label column name.&#39;): &#39;label&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;maxBlockSizeInMB&#39;, doc=&#39;maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be &gt;= 0.&#39;): 0.0, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;maxIter&#39;, doc=&#39;max number of iterations (&gt;= 0).&#39;): 10, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;predictionCol&#39;, doc=&#39;prediction column name.&#39;): &#39;prediction&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;probabilityCol&#39;, doc=&#39;Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.&#39;): &#39;probability&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;rawPredictionCol&#39;, doc=&#39;raw prediction (a.k.a. confidence) column name.&#39;): &#39;rawPrediction&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;standardization&#39;, doc=&#39;whether to standardize the training features before fitting the model.&#39;): True, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;threshold&#39;, doc=&#39;Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].&#39;): 0.5, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;tol&#39;, doc=&#39;the convergence tolerance for iterative algorithms (&gt;= 0).&#39;): 1e-06}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nLogistic regression: \n{Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;aggregationDepth&#39;, doc=&#39;suggested depth for treeAggregate (&gt;= 2).&#39;): 2, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;elasticNetParam&#39;, doc=&#39;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.&#39;): 0.0, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;family&#39;, doc=&#39;The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial&#39;): &#39;auto&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;featuresCol&#39;, doc=&#39;features column name.&#39;): &#39;features&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;fitIntercept&#39;, doc=&#39;whether to fit an intercept term.&#39;): True, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;labelCol&#39;, doc=&#39;label column name.&#39;): &#39;label&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;maxBlockSizeInMB&#39;, doc=&#39;maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be &gt;= 0.&#39;): 0.0, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;maxIter&#39;, doc=&#39;max number of iterations (&gt;= 0).&#39;): 10, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;predictionCol&#39;, doc=&#39;prediction column name.&#39;): &#39;prediction&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;probabilityCol&#39;, doc=&#39;Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.&#39;): &#39;probability&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;rawPredictionCol&#39;, doc=&#39;raw prediction (a.k.a. confidence) column name.&#39;): &#39;rawPrediction&#39;, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;regParam&#39;, doc=&#39;regularization parameter (&gt;= 0).&#39;): 0.1, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;standardization&#39;, doc=&#39;whether to standardize the training features before fitting the model.&#39;): True, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;threshold&#39;, doc=&#39;Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].&#39;): 0.5, Param(parent=&#39;LogisticRegression_9f2332faa637&#39;, name=&#39;tol&#39;, doc=&#39;the convergence tolerance for iterative algorithms (&gt;= 0).&#39;): 1e-06}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Prepare test documents, which are unlabeled.\ntest = spark.createDataFrame([\n    (4, \"spark i j k\"),\n    (5, \"l m n\"),\n    (6, \"mapreduce spark\"),\n    (7, \"apache hadoop\")\n], [\"id\", \"text\"])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf795a95-22ab-4d4d-9c94-0a64066a45f2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["prediction = cvModel.transform(test)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"979be950-3b0d-4096-80e7-eeadbbb093a0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Make predictions on test documents. cvModel uses the best model found (lrModel).\nprediction = cvModel.transform(test)\nselected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\nprint('\\n')\nfor row in selected.collect():\n    print(row)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a04dbb6a-e3a4-4309-8ddd-b01847192867"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\n\nRow(id=4, text=&#39;spark i j k&#39;, probability=DenseVector([0.2665, 0.7335]), prediction=1.0)\nRow(id=5, text=&#39;l m n&#39;, probability=DenseVector([0.9204, 0.0796]), prediction=0.0)\nRow(id=6, text=&#39;mapreduce spark&#39;, probability=DenseVector([0.4438, 0.5562]), prediction=1.0)\nRow(id=7, text=&#39;apache hadoop&#39;, probability=DenseVector([0.8587, 0.1413]), prediction=0.0)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\n\nRow(id=4, text=&#39;spark i j k&#39;, probability=DenseVector([0.2665, 0.7335]), prediction=1.0)\nRow(id=5, text=&#39;l m n&#39;, probability=DenseVector([0.9204, 0.0796]), prediction=0.0)\nRow(id=6, text=&#39;mapreduce spark&#39;, probability=DenseVector([0.4438, 0.5562]), prediction=1.0)\nRow(id=7, text=&#39;apache hadoop&#39;, probability=DenseVector([0.8587, 0.1413]), prediction=0.0)\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"4_cross_validation","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1348478196990222}},"nbformat":4,"nbformat_minor":0}
